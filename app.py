# app.py
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import easyocr

color_ranges = {
    'fire': 'B50B0E',
    'water': '015AB6',
    'wind': '1F6A0B',
    'earth': '623F23',
    'light': 'DA8D09',
    'dark': '502181'
}

def hex_to_rgb(hex_code):
    return tuple(int(hex_code[i:i+2], 16) for i in (0, 2, 4))

# ìºì‹±ìœ¼ë¡œ Readerë¥¼ í•œ ë²ˆë§Œ ë¡œë“œ
@st.cache_resource
def load_reader():
    return easyocr.Reader(['en'], gpu=False, verbose=False)

def extract_number(region, reader):
    try:
        gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)
        resized = cv2.resize(gray, None, fx=4, fy=4, interpolation=cv2.INTER_CUBIC)
        results = reader.readtext(resized, allowlist='0123456789', paragraph=False)

        if results:
            text = results[0][1]
            return int(text.strip())
    except Exception as e:
        st.error(f"ìˆ«ì ì¶”ì¶œ ì˜¤ë¥˜: {e}")
    return 0

def find_items(img_array, color_range, reader):
    img_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)
    results = {}

    for type, hex_color in color_range.items():
        target_rgb = hex_to_rgb(hex_color)
        lower_c = np.array([max(0, c - 10) for c in target_rgb])
        upper_c = np.array([min(255, c + 10) for c in target_rgb])
        
        mask = cv2.inRange(img_rgb, lower_c, upper_c)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            largest = max(contours, key=cv2.contourArea)
            if cv2.contourArea(largest) > 100:
                x, y, w, h = cv2.boundingRect(largest)
                number_region = img_rgb[y+h:y+int(h*2), x+w:x+int(w*2.3)]
                count = extract_number(number_region, reader)
                results[type] = count
            else:
                results[type] = 0
        else:
            results[type] = 0

    return results

# Streamlit UI
st.set_page_config(page_title="ê²Œì„ ì•„ì´í…œ ì¹´ìš´í„°", page_icon="ğŸ®")

st.title('ğŸ® ê²Œì„ ì•„ì´í…œ ì¹´ìš´í„°')
st.write('íšë“í•œ ì†ì„± ì•„ì´í…œ ê°œìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì„¸ì–´ë“œë¦½ë‹ˆë‹¤!')

uploaded_file = st.file_uploader("ìŠ¤í¬ë¦°ìƒ·ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['png', 'jpg', 'jpeg'])

if uploaded_file is not None:
    # ì´ë¯¸ì§€ ë¡œë“œ
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    
    # ì´ë¯¸ì§€ í‘œì‹œ
    st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), caption='ì—…ë¡œë“œëœ ì´ë¯¸ì§€', use_container_width=True)
    
    with st.spinner('ì•„ì´í…œ ê°œìˆ˜ë¥¼ ì„¸ëŠ” ì¤‘... (ì²˜ìŒ ì‹¤í–‰ì‹œ ëª¨ë¸ ë¡œë”©ìœ¼ë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)'):
        try:
            reader = load_reader()
            results = find_items(img, color_ranges, reader)
            
            # ê²°ê³¼ í‘œì‹œ
            st.success('âœ… ë¶„ì„ ì™„ë£Œ!')
            
            col1, col2, col3 = st.columns(3)
            
            emoji_map = {
                'fire': 'ğŸ”¥',
                'water': 'ğŸ’§',
                'wind': 'ğŸ’¨',
                'earth': 'ğŸŒ',
                'light': 'âœ¨',
                'dark': 'ğŸŒ™'
            }
            
            korean_map = {
                'fire': 'ë¶ˆ',
                'water': 'ë¬¼',
                'wind': 'ë°”ëŒ',
                'earth': 'ëŒ€ì§€',
                'light': 'ë¹›',
                'dark': 'ì–´ë‘ '
            }
            
            cols = [col1, col2, col3]
            for idx, (type, count) in enumerate(results.items()):
                col = cols[idx % 3]
                with col:
                    st.metric(
                        label=f"{emoji_map.get(type, '')} {korean_map.get(type, type)}", 
                        value=f"{count}ê°œ"
                    )
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.info("EasyOCR ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Streamlit Cloudì˜ ë©”ëª¨ë¦¬ ì œí•œ ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

st.markdown('---')
st.caption('Made by â¤ï¸sseong')